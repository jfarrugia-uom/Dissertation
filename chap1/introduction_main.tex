%%\textbf{Note that you may have multiple \texttt{{\textbackslash}include} statements here, e.g.\ one for each subsection.}\cofeBm{0.7}{1}{0}{3cm}{-1cm}
\chapter{Introduction}

\section{Motivation}
Humans conceptualise objects as part of classes.  For instance, a dog is a type of animal. This information
enables one to think of objects as abstract classes, which means that if a human learns that dogs bite, it might infer that other animals might bite too.  This type of knowledge inference is important to generic Artificial Intelligence. In this research, the plan is to focus on identifying the general class that a concept or entity belongs to — linguistically, this is referred
to as the hypernym.  Hypernym discovery has been a challenging task in Natural Language Processing, reflected by a number of SemEval shared tasks set in the past, which mainly focused on Taxonomy evaluation (SemEval-2015 task 17\footnote{\url{http://alt.qcri.org/semeval2015/task17/}}, SemEval-2016 task 13\footnote{\url{http://alt.qcri.org/semeval2016/task13/}}).  

\citeauthor{camacho2017we} muses about the recent neglect of taxonomy construction in research, in favour of “simply” identifying hypernymy \citep{camacho2017we}.  He blames this primarily on the reliance on hand-crafted taxonomies for the evaluation of proposed solutions, which are expensive to procure.  On the other hand, hypernym detection is appreciably easier to evaluate due to the availability of several gold-standard datasets \citep{Baroni2011, santus2015evalution, weeds2014learning}.  Despite several developments in the area of hypernym detection, Camacho-Collados argues that merely determining whether hypernymy holds between a word-pair in a binary fashion is of limited use to downstream tasks \citep{camacho2017we}.  Consider the question “Which museums are open on Sunday in London” posed to a Question Answering system.  An effective system must be able to autonomously link various building instances with the \textit{museum} concept, before filtering those that are located in London and open on a Sunday.  Thus, the binary task is recast to a hypernym discovery problem whereby given a query term, a system is expected to emit a list of the word’s potential hypernyms.  Question Answering is not the only domain which benefits from a hypernym discovery component.  Other downstream tasks include taxonomy construction \citep{wu2012probase}; and query understanding \citep{hua2017understand}.

The call to recast identification to discovery was answered by a recent SemEval committee who devised a shared task - SemEval 2018 Task 9 \footnote{\url{https://competitions.codalab.org/competitions/17119}} - that challenged participants to extract hypernyms directly from general-purpose and domain-specific corpora in English, Spanish and Italian.  This dissertation makes extensive use of the resources shipped with the task and employs techniques from the more performant submissions’ toolbox to fuel our exploration of hypernymy discovery. 

\section{Aims \& Objectives}
Research on hypernym identification, extraction and discovery has been ongoing for more than 25 years.  As a consequence, a staggering amount of techniques have been developed which attempt to solve some aspect of the problem.  Despite the time and effort, hypernym discovery has not been solved yet.  However, a recent class of algorithms known as \textit{projection learning} models, trained on word embeddings features have shown a great deal of ability at generating hypernyms for a given query term.  However, the research is currently fractured insofar that no work has attempted to unite all projection models in the literature and examine them with respect to a common experimental regime.  Moreover, we found that claims by authors attesting their model's superiority over other work to be statistically weak. Finally, the majority of the work focuses on word features extracted from word2vec embeddings thus neglegting the effect that other embeddings algorithms such as GloVe and fastText might have on projection learning models' performance.

Our aim is to develop a deep understanding of projection learning such that we can appraise the various solution critically.  The insight will then be applied on the SemEval-2018, Task 9 shared task, specifically the English, general-purpose sub-task.  To fulfill this aim, we set out the following objectives:
\begin{enumerate}
    \item Review the prevalent literature on projection learning methods to understand the mathematical background which underpins these models;
    \item Implement one or more of the models as per the relevant technical instructions;
    \item Integrate a feature from one 
\end{enumerate}



\section{Proposed Solution}
Develop common experimental setup composed of a high-quality dataset, standard evaluation metrics and scoring system which we will use to appraise four projection learning model types.


\section{Document Structure}
We present the background required to understand this task, and the experiments we carried out, by surveying the salient contributions made to the areas of hypernymy identification and discovery.   We start from the earliest handpicked pattern-based methods and see how even this relatively simple technique can be leveraged to induce a large, complex taxonomy.  

Dependency paths were later used to discover hypernym-containing patterns automatically.  Although never abandoned, pattern-centric approaches eventually gave way to distributional methods and \acl{VSM}s.  There are several \ac{VSM} flavours, each varying in terms of context type and feature weighting mechanism; we will introduce the main types used in the reviewed literature.  Several unsupervised metrics were developed that given the vector representation of two words, scored the likelihood that the words were bound by hypernymy based on their respective dimensional contexts.

When word embeddings burst onto the scene in 2013 \citep{mikolov2013distributed}, supervised methods involving various combinations of the hyponym and hypernym vector embeddings fed into a classifier acquired outstanding results in the hypernym identification binary task.  Closer inspection by researchers sceptical about these results underscored these methods’ proneness to overfitting the training data. In doing so, they shone a light on the limitation of the identification task and encouraged the NLP research community to recast identification to hypernym discovery.  We then move on to a variant of supervised learning which attempts to learn a linear projection transformation matrix which when applied to a hyponym vector, yields a vector close to its hypernym.  This research project is particularly focused on these methods, considering their relative success in generating hypernyms.  

We close the background chapter by reviewing the SemEval 2018 Task 9 shared task \citep{camacho2018semeval}, concentrating on the methodology used to create the training and testing datasets which were part automated and part crowd-sourced.  Setting aside the popular precision/recall/\(F1\) evaluation measures, the task’s organisers propose a new set of metrics, borrowed from \ac{IR} that are suited to the ranking nature of the problem.  Finally, we examine the submitted models focusing on those which peruse of projection learning techniques to propose hypernyms for the given candidate terms.
